{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sample(batch_size, N_agents, in_dim = None, L = None):\n",
    "    \"\"\" \n",
    "        generates an inital states in [0,L1] x [0,L2] x ... x [0, Ln] of shape [Batch_size, in_dim]\n",
    "    \"\"\"\n",
    "    if in_dim is None and L is None:\n",
    "        raise ValueError(\"Need either L or in dim to be set\")\n",
    "    if in_dim is None:\n",
    "        in_dim = len(L)\n",
    "    if L is None:\n",
    "        L = [1. for _ in range(in_dim)]\n",
    "    x = torch.rand(batch_size, N_agents, in_dim).abs()\n",
    "    for i in range(len(L)):\n",
    "        x[:, :, i] = torch.clamp(x[:, :, i], max=L[i])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Agents = 2\n",
    "in_dim = 1\n",
    "batch_size = 32\n",
    "n_samples = 1024\n",
    "timesteps = 100\n",
    "lam = 0.5\n",
    "control_energy_reg = 1e-6 ### regularization on maximum control energy\n",
    "k_max = 64\n",
    "u_max = 100 # does not do anything currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\n",
    "        torch.tensor([[.0, .3]]),\n",
    "        torch.tensor([[.6, .9]])\n",
    "        ]\n",
    "weights = [.5, .5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Ergodic_Loss\n",
    "import Recursive_KAN\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\JP\\Documents\\TU Berlin\\Master\\Code_RNN\\Recursive_kan\\Ergodic_Loss.py') \n",
    "sys.path.append(r'C:\\Users\\JP\\Documents\\TU Berlin\\Master\\Code_RNN\\Recursive_kan\\Recursive_KAN.py') \n",
    "import importlib\n",
    "importlib.reload(Ergodic_Loss)\n",
    "importlib.reload(Recursive_KAN)\n",
    "\n",
    "criterion = Ergodic_Loss.Ergodicity_Loss(N_Agents = N_Agents, n_timesteps = timesteps,L = None, in_dim = in_dim, k_max = k_max,control_energy_reg = control_energy_reg, density = 'mixture_uniform', regions = regions, weights = weights)\n",
    "model = Recursive_KAN.KAN_RNN_Layer(N_Agents = N_Agents, in_dim = in_dim, hidden = 256, depth = 2, n_timesteps = timesteps,sys_param_lam= lam, u_max = u_max, network_type='multi')\n",
    "model.init_hidden(batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5  # Number of epochs to train\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "model.train()  # Set the model to training mode\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0 \n",
    "    for samples in range(n_samples // batch_size):\n",
    "        model.init_hidden(batch_size = batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        control , outputs = model(gen_sample(batch_size = batch_size, N_agents = N_Agents, in_dim = in_dim))\n",
    "        loss = criterion(x = outputs, u = control) + model.penalty #* 1e-2 ## punishment on leaving the rect\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / n_samples\n",
    "    train_loss.append(avg_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.6f}\")\n",
    "plt.plot(train_loss)\n",
    "plt.title(f'train_loss uniform distribution with system dynamic x(k + 1) = x(k) + {lam} u')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot trajectory\n",
    "print(model.N_Agents)\n",
    "inital_state = gen_sample(batch_size = 1, N_agents = N_Agents, in_dim = in_dim)\n",
    "#print(inital_state)\n",
    "model.init_hidden(batch_size = 1)\n",
    "outs, control = model(inital_state)\n",
    "print(outs.shape)\n",
    "#print(outs)\n",
    "for i in range(N_Agents):\n",
    "    plt.plot(outs[:,:,i,:].squeeze().detach(), label = f'Agent {i}')\n",
    "plt.title(f'Trajectories uniform distribution over 1D-rectangular system dynamic x(k + 1) = x(k) + {lam} u, constraint on energy {control_energy_reg} (|| u ||)^2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
